Speaker 1 (00:00):
Hi. In this video we'll talk about derivations parsing and ambiguity. When discussing regular languages, we saw that linear grammars can only have a single variable in their potential format at a time. However, grammars that are not linear can have potential forms with multiple variables. And this allows us a choice in deciding what order we replace those variables in order to ignore differences in derivations that are due. Just to the order in which we choose to replace these variables, we can restrict ourselves to either a leftmost derivation or a rightmost derivation. In a leftmost derivation, we always replace the leftmost variable in the ental form. And the idea for rightmost derivations is what you would expect.

(00:57):
We can also use a parse tree. That's another way of representing a derivation that ignores a choice of order. And we can see an example here. There's a slight notational difference from what you're used to here. They use an epsilon to represent the empty string instead of a lambda. But here from the designated start symbol we generate, sorry. We apply one of the production rules to go from S to ab, and then from A, we can replace that with a terminal symbol A and another variable A. Then maybe we go over and we replace the variable B with a terminal symbol B. And then we go over here and we replace this variable A with the terminal symbol A and another variable A, and then we replace this variable A with the empty string. And it doesn't matter what order we do these replacements in, we still get the same tree and we can read off the final string that is produced just by reading across the leaves of this derivation tree. And that's a B. The empty string we can skip over because it doesn't add to the string. It doesn't have any symbols. So a B is the string that's produced in this derivation.

(02:35):
A membership algorithm is one that tells us if a certain string can be generated by a certain grammar and finding the sequence of productions that generates the string is called parsing the string. And this tells us the meaning of that string. One membership algorithm is called brute force parsing, and it consists of applying all possible productions to the left most variable of each ental form. And if the string is part of the language of that grammar, then this method will eventually give us a leftmost derivation of the string. However, brute force parsing is very inefficient, and it also might not ever terminate for strings that are not in the language of that grammar. We can get around that last point by ruling out empty productions in unit productions. And the reason for that is because if the grammar contains empty productions in unit productions, then the syn potential form could grow and shrink throughout the generation of a particular string, and we wouldn't know when we might safely stop that particular sequence of productions. Maybe we could still arrive at the string we're trying to get to, and maybe we can't. We're not sure. However, if a grammar does not have any empty productions or any unit productions, then that means that the sent potential form will always be increasing in length, and that means that in a particular sequence of productions, if we ever get to a point where the potential form is longer than the string we're trying to generate, we know that we can stop that particular line of inquiry and we can go back and try something else.

(04:28):
However, even with that change, brute force parsing is still inefficient. The good news is that linear time parsing algorithms are known for restricted but important special cases of context free languages such as S grammars. I don't define an S grammar here, but they are defined in your textbook reading. Many features of common programming languages can be described by S grammars. So it's not just an esoteric abstract example, it's something that has real application. A context free grammar is ambiguous if any string in the language has at least two distinct derivation trees. So they don't just differ because of the order in which we replaced variables. But there's, even if we compare leftmost derivations, or if we compare derivation trees, we can see that there's a difference in how the strings were produced.

(05:36):
Ideally, we would like the meaning of statements and programming languages to be unambiguous. So we would only like for there to be a single way of parsing a particular statement in a programming language. Often if we do have an ambiguous grammar, we can replace it with an equivalent unambiguous grammar that generates the same language, so that's good. However, if every grammar that generates a particular language is ambiguous, then the language itself is said to be inherently ambiguous. So the difference there is that ambiguous applies to a grammar, but inherently ambiguous applies to a language. Hopefully that distinction is clear. And that brings us to the close of this video. As always, if you have questions, please post them in the forums. I'm happy to answer them, and I'll see you next time.

